Training information

epoch, type, accuracy, MSE, prec. label 0,prec. label 1,prec. label 2,prec. label 3,prec. label 4,prec. label 5,prec. label 6,prec. label 7,prec. label 8,prec. label 9
0, train, 0.6087092405458902, 0.09588101107307244, 1.0,1.0,0.99,0.98,0.99,0.99,1.0,0.99,0.99,0.98
0, val, 0.7486880466472303, 0.05476939409792322, 0.99,1.0,0.98,0.98,0.99,1.0,1.0,0.99,0.99,0.99
1, train, 0.8066881966871549, 0.03950381024450227, 1.0,1.0,0.99,0.99,0.99,0.99,1.0,0.99,0.99,0.99
1, val, 0.8128279883381925, 0.04170184936633049, 1.0,1.0,0.99,0.99,0.99,1.0,1.0,1.0,1.0,0.99
2, train, 0.8462548182102302, 0.030357872638313754, 1.0,1.0,1.0,0.99,0.99,0.99,1.0,1.0,1.0,0.99
2, val, 0.8421491045397751, 0.035616175653839906, 1.0,1.0,0.99,0.99,0.99,1.0,1.0,0.99,1.0,0.99
3, train, 0.872320033336806, 0.02469947472992315, 1.0,1.0,1.0,0.99,0.99,1.0,1.0,1.0,1.0,0.99
3, val, 0.8521449396084965, 0.031939018282276375, 1.0,0.99,0.99,0.99,1.0,1.0,1.0,1.0,0.99,0.98
4, train, 0.8854464006667361, 0.021486955886440836, 1.0,1.0,1.0,0.99,1.0,1.0,1.0,1.0,1.0,0.99
4, val, 0.8738025822573927, 0.0291742520060896, 1.0,1.0,0.99,0.99,1.0,0.99,1.0,1.0,0.99,0.99
5, train, 0.8972601312636733, 0.018829805862279413, 1.0,1.0,1.0,0.99,1.0,1.0,1.0,1.0,1.0,0.99
5, val, 0.8718034152436485, 0.0280915317376542, 1.0,1.0,1.0,1.0,0.99,0.99,1.0,0.99,1.0,0.99
6, train, 0.9074486925721429, 0.016610666248530647, 1.0,1.0,1.0,0.99,1.0,1.0,1.0,1.0,1.0,0.99
6, val, 0.887963348604748, 0.026389315275048706, 1.0,1.0,0.99,0.99,1.0,1.0,1.0,1.0,0.99,0.99
7, train, 0.9143244087925826, 0.014723897410373561, 1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.99
7, val, 0.8919616826322365, 0.02571248920721937, 1.0,1.0,0.99,0.99,0.99,1.0,1.0,0.99,0.99,0.99
8, train, 0.9211376185019273, 0.013412982758274364, 1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0
8, val, 0.8827155351936693, 0.028298734532899703, 1.0,1.0,0.99,1.0,1.0,0.99,1.0,1.0,1.0,0.98
9, train, 0.9274716116262111, 0.012315921198351702, 1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.99
9, val, 0.8967097042898792, 0.02657391391687832, 1.0,1.0,1.0,0.99,0.99,1.0,1.0,0.99,0.99,0.99
10, train, 0.9328888425877696, 0.011074761865162751, 1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0
10, val, 0.8883798417326114, 0.029278417133404455, 1.0,1.0,0.99,0.99,0.97,0.99,1.0,0.99,1.0,0.99
11, train, 0.9373684758829045, 0.009998206324065534, 1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0
11, val, 0.9023740108288213, 0.024479290153353754, 0.99,1.0,0.99,0.99,0.99,1.0,1.0,0.99,0.99,0.99
12, train, 0.9401812688821752, 0.009501042594304029, 1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0
12, val, 0.9088713036234902, 0.02380079476361018, 1.0,1.0,1.0,0.99,0.99,0.99,1.0,1.0,1.0,0.99
13, train, 0.9447442441921033, 0.008778581907059888, 1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0
13, val, 0.9136193252811329, 0.023720607818915985, 1.0,1.0,0.99,0.99,0.99,1.0,1.0,0.99,1.0,0.99
14, train, 0.9478695697468487, 0.007795070733386304, 1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0
14, val, 0.9084548104956268, 0.02451405065043603, 1.0,1.0,0.99,0.99,0.99,1.0,1.0,1.0,1.0,0.99
15, train, 0.9514741118866549, 0.0073418952624221484, 1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0
15, val, 0.9112869637650979, 0.02400337432340617, 1.0,1.0,0.99,0.99,1.0,1.0,1.0,0.99,1.0,0.99
16, train, 0.9554120220856339, 0.006740136428506563, 1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0
16, val, 0.9107038733860892, 0.02392507238738361, 1.0,1.0,1.0,1.0,0.99,0.99,1.0,1.0,1.0,0.99
17, train, 0.9574747369517658, 0.006334442339522478, 1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0
17, val, 0.9118700541441066, 0.02475976526955517, 1.0,1.0,0.99,0.99,1.0,0.99,1.0,0.99,0.99,0.99
18, train, 0.9626627773726429, 0.005924695773344068, 1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0
18, val, 0.9197001249479384, 0.02295586716435031, 1.0,1.0,0.99,0.99,0.99,0.99,1.0,0.99,0.99,0.99
19, train, 0.9638920720908428, 0.005622856526937142, 1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0
19, val, 0.9187005414410663, 0.023809315185706146, 1.0,1.0,0.99,0.99,0.99,0.99,1.0,1.0,0.99,0.99
20, train, 0.9658714449421815, 0.005279673359179451, 1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0
20, val, 0.9183673469387755, 0.02315108581757675, 1.0,1.0,1.0,0.99,0.99,1.0,1.0,0.99,0.99,0.99
21, train, 0.9673924367121575, 0.005045881143023668, 1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0
21, val, 0.9201999167013745, 0.023195428806442434, 1.0,1.0,0.99,0.99,0.99,0.99,1.0,0.99,0.99,0.99
22, train, 0.9721012605479737, 0.004579670852565756, 1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0
22, val, 0.917201166180758, 0.02355394996961883, 0.99,1.0,1.0,1.0,0.99,1.0,1.0,0.99,1.0,0.99
23, train, 0.9732680487550787, 0.004453143555097475, 1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0
23, val, 0.9207830070803832, 0.022725056706846346, 1.0,1.0,0.99,0.99,0.99,1.0,1.0,0.99,0.99,0.99
24, train, 0.9752265861027191, 0.004306513807203672, 1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0
24, val, 0.9226155768429821, 0.02287238166977421, 1.0,1.0,0.99,1.0,0.99,0.99,1.0,0.99,1.0,0.99
25, train, 0.9771851234503595, 0.00406325331187029, 1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0
25, val, 0.92161599333611, 0.022230897126836537, 1.0,1.0,0.99,0.99,0.99,0.99,1.0,1.0,1.0,0.99
26, train, 0.9790603187832065, 0.0038947666192523547, 1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0
26, val, 0.924198250728863, 0.022339554691745363, 1.0,1.0,0.99,0.99,0.99,1.0,1.0,0.99,1.0,0.99
27, train, 0.9822898218564434, 0.0038004570859732066, 1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0
27, val, 0.9238650562265722, 0.02234904194729601, 1.0,1.0,0.99,0.99,0.99,1.0,1.0,1.0,0.99,0.99
28, train, 0.9832482550265653, 0.003709757887978243, 1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0
28, val, 0.923948354852145, 0.02216475832162988, 1.0,1.0,0.99,0.99,0.99,1.0,1.0,0.99,1.0,0.99
29, train, 0.9852692988853006, 0.0035850714154672956, 1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0
29, val, 0.9248646397334443, 0.022268714216448448, 1.0,1.0,0.99,0.99,0.99,1.0,1.0,0.99,0.99,0.99
30, train, 0.9868319616626732, 0.0035144994395910315, 1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0
30, val, 0.9251978342357351, 0.02234598767202101, 1.0,1.0,0.99,0.99,0.99,1.0,1.0,0.99,1.0,0.99
31, train, 0.9873320137514324, 0.003497590634454928, 1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0
31, val, 0.9245314452311537, 0.022252478493530816, 1.0,1.0,0.99,0.99,0.99,1.0,1.0,0.99,0.99,0.99
32, train, 0.987019481195958, 0.003438226840803131, 1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0
32, val, 0.9235318617242816, 0.022192495380137123, 1.0,1.0,0.99,0.99,0.99,1.0,1.0,0.99,0.99,0.99
33, train, 0.9879779143660798, 0.0033928279154692535, 1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0
33, val, 0.9258642232403166, 0.022195395550168244, 1.0,1.0,0.99,0.99,0.99,1.0,1.0,0.99,0.99,0.99
34, train, 0.9890821960620898, 0.0033461412981709055, 1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0
34, val, 0.9259475218658892, 0.02234156177752493, 1.0,1.0,0.99,0.99,0.99,1.0,1.0,0.99,0.99,0.99
35, train, 0.9897280966767371, 0.003322737570990774, 1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0
35, val, 0.9255310287380258, 0.022368828035078586, 1.0,1.0,0.99,0.99,0.99,1.0,1.0,0.99,0.99,0.99
36, train, 0.9896030836545473, 0.0033077289689973327, 1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0
36, val, 0.9258642232403166, 0.022344372734411155, 1.0,1.0,0.99,0.99,0.99,1.0,1.0,0.99,0.99,0.99
37, train, 0.9900406292322117, 0.0032771323633154262, 1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0
37, val, 0.9257809246147438, 0.02219060391574961, 1.0,1.0,0.99,0.99,0.99,1.0,1.0,0.99,1.0,0.99
38, train, 0.9898322741952287, 0.003246793112541724, 1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0
38, val, 0.9256976259891712, 0.022233600283096067, 1.0,1.0,0.99,0.99,0.99,1.0,1.0,0.99,1.0,0.99
39, train, 0.9909782268986352, 0.003195089372340929, 1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0
39, val, 0.9259475218658892, 0.022115849891255902, 1.0,1.0,0.99,0.99,0.99,1.0,1.0,0.99,1.0,0.99
40, train, 0.9901656422544015, 0.0031955210222453004, 1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0
40, val, 0.9253644314868804, 0.022334626437541673, 1.0,1.0,0.99,0.99,0.99,1.0,1.0,0.99,1.0,0.99
Test information

accuracy, mse, prec. label 0,prec. label 1,prec. label 2,prec. label 3,prec. label 4,prec. label 5,prec. label 6,prec. label 7,prec. label 8,prec. label 9
0.9275, 0.022585726448276687, 1.0,1.0,0.99,0.99,0.99,1.0,1.0,1.0,0.99,0.99