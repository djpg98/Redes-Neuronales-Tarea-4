Training information

epoch, type, accuracy, MSE, prec. label 0,prec. label 1,prec. label 2,prec. label 3,prec. label 4,prec. label 5,prec. label 6,prec. label 7,prec. label 8,prec. label 9
0, train, 0.3819254265852117, 0.16733478742338345, 1.0,1.0,0.99,0.99,0.99,0.96,1.0,0.99,0.99,0.95
0, val, 0.610079575596817, 0.09278394794488698, 0.98,1.0,0.98,0.95,0.97,1.0,1.0,0.98,1.0,1.0
1, train, 0.6826767783161295, 0.06831407217651446, 1.0,1.0,0.99,0.99,0.99,0.99,1.0,0.99,0.99,0.97
1, val, 0.6949602122015915, 0.07348121716499861, 0.98,1.0,1.0,1.0,0.95,0.98,1.0,0.98,0.97,1.0
2, train, 0.7492451372796854, 0.05011257987641208, 1.0,1.0,0.99,0.99,0.99,0.99,1.0,0.99,0.99,0.98
2, val, 0.7480106100795756, 0.05972892235452565, 1.0,1.0,0.97,0.98,1.0,1.0,1.0,0.98,0.98,0.98
3, train, 0.7921494277087283, 0.04134613469118247, 1.0,1.0,0.99,0.99,0.99,0.99,1.0,1.0,1.0,0.98
3, val, 0.7281167108753316, 0.06212073772747111, 1.0,1.0,0.96,0.97,0.98,1.0,0.98,0.98,0.98,1.0
4, train, 0.8161645951829225, 0.03357163166564472, 1.0,1.0,1.0,1.0,0.99,1.0,1.0,1.0,1.0,0.99
4, val, 0.773209549071618, 0.04906560270710066, 1.0,1.0,0.98,1.0,0.98,1.0,0.98,0.98,1.0,0.98
5, train, 0.8406713011726704, 0.029029228687548238, 1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.99
5, val, 0.8023872679045093, 0.04548132344459085, 1.0,1.0,0.99,1.0,0.97,0.98,0.98,0.98,1.0,1.0
6, train, 0.8545748191840461, 0.02518281942365476, 1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.99
6, val, 0.8129973474801061, 0.0461715099935606, 1.0,1.0,0.98,0.98,0.98,1.0,0.98,0.98,1.0,0.98
7, train, 0.8675654799522505, 0.021549675147907593, 1.0,1.0,1.0,0.99,1.0,1.0,1.0,1.0,1.0,0.99
7, val, 0.8222811671087533, 0.0459404951615202, 1.0,1.0,0.97,0.98,0.98,0.98,0.99,0.98,1.0,0.98
8, train, 0.8806263605083913, 0.019181609784766476, 1.0,1.0,1.0,1.0,0.99,1.0,1.0,1.0,1.0,0.99
8, val, 0.8315649867374005, 0.043699030523043116, 1.0,1.0,0.98,1.0,0.98,1.0,0.98,0.98,0.98,0.98
9, train, 0.8917913067902535, 0.017355075568048432, 1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.99
9, val, 0.8355437665782494, 0.040282928601831074, 1.0,1.0,0.97,1.0,0.98,1.0,0.98,0.98,1.0,0.99
10, train, 0.8981110877045151, 0.015054976553070094, 1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.99
10, val, 0.8395225464190982, 0.04095187723367183, 1.0,1.0,0.97,1.0,0.98,1.0,0.98,0.97,0.97,1.0
11, train, 0.9052032862860754, 0.013707686466518357, 1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0
11, val, 0.8395225464190982, 0.04024436842033384, 1.0,1.0,0.98,1.0,0.98,1.0,1.0,0.97,0.98,0.98
12, train, 0.9156660346885752, 0.012248783599269907, 1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0
12, val, 0.8474801061007957, 0.04231183015398141, 1.0,1.0,0.99,1.0,0.98,1.0,0.99,0.97,0.98,1.0
13, train, 0.9237413103012428, 0.01107039162722003, 1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0
13, val, 0.8647214854111406, 0.03679486060331132, 1.0,1.0,0.97,1.0,0.98,1.0,0.98,0.97,0.98,0.99
14, train, 0.9280949371532898, 0.010263564791767961, 1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0
14, val, 0.8488063660477454, 0.03851209144975625, 1.0,1.0,0.98,1.0,0.98,1.0,0.99,0.97,0.98,0.98
15, train, 0.9338529597640615, 0.009364008094871404, 1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0
15, val, 0.8474801061007957, 0.041889814946793155, 1.0,1.0,0.97,1.0,0.95,1.0,0.99,0.98,0.98,0.99
16, train, 0.9390492240713433, 0.008833700321948471, 1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0
16, val, 0.8461538461538461, 0.037331293480051875, 1.0,1.0,0.96,0.99,1.0,1.0,0.98,0.98,0.98,0.98
17, train, 0.9429815321957727, 0.008195114418383272, 1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0
17, val, 0.8580901856763926, 0.03747063784084269, 1.0,1.0,0.97,1.0,0.97,1.0,0.98,0.98,0.98,0.99
18, train, 0.9487395548065445, 0.007615597338297846, 1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0
18, val, 0.8527851458885941, 0.03725062565521416, 1.0,1.0,0.98,1.0,0.98,1.0,0.98,0.98,0.98,0.99
19, train, 0.9540060389017625, 0.007124525841404611, 1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0
19, val, 0.8580901856763926, 0.03749083886043937, 1.0,1.0,0.97,1.0,0.97,1.0,0.98,0.97,0.98,0.99
20, train, 0.9616599957868127, 0.006778318795717409, 1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0
20, val, 0.8580901856763926, 0.038641251014745366, 1.0,1.0,0.97,1.0,0.97,1.0,0.99,0.98,0.98,0.99
21, train, 0.9636963696369637, 0.006584408068177458, 1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0
21, val, 0.8673740053050398, 0.03833194699707827, 1.0,1.0,0.99,1.0,0.98,1.0,0.99,0.99,0.98,0.98
22, train, 0.9684010954286918, 0.006391883381251975, 1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0
22, val, 0.8527851458885941, 0.03849826688923818, 1.0,1.0,0.97,1.0,0.97,1.0,0.98,0.98,0.98,0.98
23, train, 0.9701565901270978, 0.006205493971993366, 1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0
23, val, 0.8594164456233422, 0.03738156587807708, 1.0,1.0,0.97,1.0,0.97,1.0,0.98,0.98,0.98,0.98
24, train, 0.9717014254616951, 0.006082826175157792, 1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0
24, val, 0.8647214854111406, 0.037317062487280256, 1.0,1.0,0.97,1.0,0.98,1.0,0.99,0.98,0.98,0.98
25, train, 0.9716312056737588, 0.006007792954916247, 1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0
25, val, 0.8554376657824934, 0.038448778661484814, 1.0,1.0,0.97,1.0,0.97,1.0,0.98,0.98,0.98,0.98
26, train, 0.9732462607962924, 0.005799863353807705, 1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0
26, val, 0.8594164456233422, 0.0370857808670757, 1.0,1.0,0.97,1.0,0.97,1.0,0.99,0.99,0.98,0.98
27, train, 0.9722631837651851, 0.005676102080154945, 1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0
27, val, 0.8647214854111406, 0.036732174651417204, 1.0,1.0,0.97,1.0,0.98,1.0,0.98,0.98,0.98,0.98
28, train, 0.9757741731619971, 0.005464650471808378, 1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0
28, val, 0.863395225464191, 0.036836548091677704, 1.0,1.0,0.97,1.0,0.98,1.0,0.98,0.98,0.98,0.98
29, train, 0.979285162558809, 0.005326250799076458, 1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0
29, val, 0.8594164456233422, 0.03817686828190215, 1.0,1.0,0.97,1.0,1.0,1.0,0.99,0.98,0.98,0.98
30, train, 0.9795660417105541, 0.005243241627992499, 1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0
30, val, 0.8647214854111406, 0.03611726857846202, 1.0,1.0,0.97,1.0,0.98,1.0,0.98,0.98,0.98,0.98
31, train, 0.9830770311073661, 0.005139151322799511, 1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0
31, val, 0.8647214854111406, 0.03602418502346332, 1.0,1.0,0.97,1.0,0.98,1.0,0.98,0.98,0.98,0.98
32, train, 0.9849729653816446, 0.0050685206550554794, 1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0
32, val, 0.8660477453580901, 0.03611880232079395, 1.0,1.0,0.97,1.0,0.98,1.0,0.99,0.98,0.98,0.98
33, train, 0.9848325258057721, 0.005018903099071916, 1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0
33, val, 0.870026525198939, 0.035991607340589295, 1.0,1.0,0.97,1.0,0.98,1.0,0.99,0.97,0.98,0.99
34, train, 0.9853240643213258, 0.0049810442610679845, 1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0
34, val, 0.8687002652519894, 0.0362711679408598, 1.0,1.0,0.97,1.0,0.98,1.0,0.98,0.98,0.98,0.98
35, train, 0.985113404957517, 0.0049435524189432025, 1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0
35, val, 0.8607427055702918, 0.0364129159773736, 1.0,1.0,0.97,1.0,0.98,1.0,0.98,0.97,0.98,0.98
36, train, 0.9849027455937083, 0.0048998884828943745, 1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0
36, val, 0.8687002652519894, 0.03624578609622548, 1.0,1.0,0.97,1.0,0.98,1.0,0.98,0.97,0.98,0.98
37, train, 0.9863071413524331, 0.004798538235800604, 1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0
37, val, 0.8660477453580901, 0.03635198039469745, 1.0,1.0,0.97,1.0,0.98,1.0,0.98,0.97,0.98,0.99
38, train, 0.9864475809283056, 0.004732621718370445, 1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0
38, val, 0.8647214854111406, 0.03625238360891456, 1.0,1.0,0.97,1.0,0.98,1.0,0.99,0.97,0.98,0.98
39, train, 0.9870795590197318, 0.004663599514031805, 1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0
39, val, 0.8620689655172413, 0.03732177430332314, 1.0,1.0,0.97,1.0,0.98,1.0,0.98,0.97,0.98,0.98
40, train, 0.9852538445333895, 0.004655124741029985, 1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0
40, val, 0.8673740053050398, 0.036110569329644765, 1.0,1.0,0.97,1.0,0.98,1.0,0.98,0.97,0.98,0.99
41, train, 0.9856049434730707, 0.004595522362197979, 1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0
41, val, 0.863395225464191, 0.036636925563156036, 1.0,1.0,0.97,1.0,0.98,1.0,0.99,0.97,0.98,0.98
42, train, 0.9870093392317956, 0.004518426381036562, 1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0
42, val, 0.8687002652519894, 0.03614978497767256, 1.0,1.0,0.97,1.0,0.98,1.0,0.99,0.97,0.98,0.99
43, train, 0.9877115371111579, 0.004442800630878643, 1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0
43, val, 0.870026525198939, 0.035902874431371634, 1.0,1.0,0.97,1.0,0.98,1.0,0.99,0.97,0.98,0.99
44, train, 0.9888350537181377, 0.00442517279968063, 1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0
44, val, 0.8673740053050398, 0.03636102597434572, 1.0,1.0,0.97,1.0,0.98,1.0,0.99,0.97,0.98,0.98
45, train, 0.9892563724457553, 0.004403189824471244, 1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0
45, val, 0.8660477453580901, 0.03667180480174254, 1.0,1.0,0.97,1.0,0.98,1.0,0.99,0.97,0.98,0.98
46, train, 0.9885541745663928, 0.004385929140482996, 1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0
46, val, 0.8753315649867374, 0.03632074934508005, 1.0,1.0,0.97,1.0,0.98,1.0,0.99,0.97,0.98,0.99
47, train, 0.9890457130819464, 0.004323649017000375, 1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0
47, val, 0.8740053050397878, 0.03638521512928078, 1.0,1.0,0.97,1.0,0.98,1.0,0.99,0.97,0.98,0.99
48, train, 0.9897479109613089, 0.004282197404474666, 1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0
48, val, 0.8793103448275862, 0.03704304668678702, 1.0,1.0,0.97,1.0,0.98,1.0,0.99,0.97,0.98,0.99
49, train, 0.9895372515975002, 0.004226922402451444, 1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0
49, val, 0.8740053050397878, 0.036676001663906874, 1.0,1.0,0.97,1.0,0.98,1.0,0.99,0.97,0.98,0.99
Test information

accuracy, mse, prec. label 0,prec. label 1,prec. label 2,prec. label 3,prec. label 4,prec. label 5,prec. label 6,prec. label 7,prec. label 8,prec. label 9
0.8909, 0.030135670871071146, 1.0,1.0,1.0,1.0,0.99,0.99,1.0,0.99,0.99,0.98